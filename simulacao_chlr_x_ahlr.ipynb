{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOiZDLR6sxwLrXrYu4HzNz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaniellyBenicio/simulacao_revisao_espacada/blob/main/simulacao_chlr_x_ahlr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_Qtwj3Lz481"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import truncnorm\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "N_ROUNDS = 3\n",
        "FIXED_SEED_INIT = 42\n",
        "THRESHOLDS_P = [0.9, 0.7]\n",
        "HORIZONTES_A_TESTAR = [15, 30, 60, 90, 120, 150, 180]\n",
        "\n",
        "\n",
        "N_STUDENTS = 100\n",
        "N_GROUP = 50\n",
        "\n",
        "N_QUESTIONS = 500\n",
        "N_SUBTEMAS = 5\n",
        "SUBTEMAS = [f\"S{i+1}\" for i in range(N_SUBTEMAS)]\n",
        "N_QUESTIONS_PER_SUBTEMA = N_QUESTIONS // N_SUBTEMAS\n",
        "\n",
        "CARGA_PRATICA = 4\n",
        "MIN_SPACING_INTERVAL = 10\n",
        "H_MIN = 1.0\n",
        "H_MAX = 365.0\n",
        "K_ABILITY_UPDATE = 32\n",
        "DIFFICULTY_RANGE_MARGIN = 150\n",
        "\n",
        "# Fallbacks\n",
        "FALLBACK_NONE = 'none'\n",
        "FALLBACK_LEVEL1 = 'level1_urgency'\n",
        "FALLBACK_LEVEL2 = 'level2_item_selection'\n",
        "FB_REASON_OK = 'ok'\n",
        "FB_REASON_NO_URGENT_SUBTOPIC = 'no_subtopic_below_threshold'\n",
        "FB_REASON_NO_ITEMS_IN_RANGE = 'no_items_in_difficulty_range'\n",
        "FB_REASON_MSI_BLOCKED = 'msi_blocked_all_candidates'\n",
        "FB_REASON_USED_ALL_SUBTEMA = 'range_empty_used_all_subtema'\n",
        "\n",
        "def get_truncated_normal(mean=500, sd=150, low=0, high=1000, size=None):\n",
        "    return truncnorm((low-mean)/sd, (high-mean)/sd, loc=mean, scale=sd).rvs(size)\n",
        "\n",
        "def fibonacci(n):\n",
        "    if n <= 1: return 1\n",
        "    a, b = 1, 1\n",
        "    for _ in range(2, n+1):\n",
        "        a, b = b, a + b\n",
        "        if a > 1_000_000: return b\n",
        "    return b\n",
        "\n",
        "def simple_logistic_prob(ability, difficulty):\n",
        "    return np.clip(1 / (1 + np.exp(-(ability - difficulty)/100)), 0.01, 0.99)\n",
        "\n",
        "def generalized_probability(student, question, dt, h, h_cost=1.0):\n",
        "    h_cost = compute_h_cost(student, question)\n",
        "    base = simple_logistic_prob(student.ability, question.difficulty)\n",
        "    retention = 0.5 ** (dt * h_cost / h)\n",
        "    #if student.group == \"G2\":\n",
        "    #print(f\"Gr {student.group} | Aluno {student.ability} | Id_q {question.q_id} Dificuldade {question.difficulty} | h_cost {h_cost} | dt {dt} | h {h} |HLR {retention}\")\n",
        "    return np.clip(base * retention, 0.01, 0.99), retention, h_cost\n",
        "\n",
        "def sample_with_overdispersion(p, kappa=50):\n",
        "    alpha = max(p * kappa, 1e-6)\n",
        "    beta = max((1-p) * kappa, 1e-6)\n",
        "    p_pert = np.random.beta(alpha, beta)\n",
        "    return 1 if np.random.random() < p_pert else 0\n",
        "\n",
        "class Question:\n",
        "    def __init__(self, q_id, subtema, difficulty):\n",
        "        self.q_id = q_id\n",
        "        self.subtema = subtema\n",
        "        self.difficulty = difficulty\n",
        "        self.last_day_seen = 0\n",
        "\n",
        "class Student:\n",
        "    def __init__(self, s_id, group, threshold, ability):\n",
        "        self.s_id = s_id\n",
        "        self.group = group\n",
        "        self.threshold = threshold\n",
        "        self.ability = ability\n",
        "        #self.h_cost = 1.0 if group == \"G1\" else 1 - (ability/1000)\n",
        "        self.h_cost = 1.0\n",
        "        self.questions_state = {}\n",
        "        self.subtema_h = {st: H_MIN for st in SUBTEMAS}\n",
        "        self.subtema_last_seen = {st: 0 for st in SUBTEMAS}\n",
        "        self.subtema_correct_streak = {st: 0 for st in SUBTEMAS}\n",
        "        self.subtema_error_streak = {st: 0 for st in SUBTEMAS}\n",
        "\n",
        "def update_half_life(q, student, result):\n",
        "    st = q.subtema\n",
        "    ratio = student.ability / (q.difficulty + 1e-6)\n",
        "    h = student.subtema_h[st]\n",
        "    if result == 1:\n",
        "        student.subtema_correct_streak[st] += 1\n",
        "        student.subtema_error_streak[st] = 0\n",
        "        inc = ratio * fibonacci(student.subtema_correct_streak[st])\n",
        "        h_new = h + inc\n",
        "    else:\n",
        "        student.subtema_error_streak[st] += 1\n",
        "        student.subtema_correct_streak[st] = 0\n",
        "        inc = (q.difficulty + 1e-6) / (student.ability + 1e-6) * fibonacci(student.subtema_error_streak[st])\n",
        "        h_new = H_MIN + inc / 10\n",
        "    student.subtema_h[st] = np.clip(h_new, H_MIN, H_MAX)\n",
        "\n",
        "def compute_h_cost(student, question):\n",
        "    if student.group == \"G1\":\n",
        "        return question.difficulty / 1000\n",
        "    else:\n",
        "        return 1 - (student.ability / 1000)\n",
        "\n",
        "def update_ability(student, q, result):\n",
        "    p_exp = simple_logistic_prob(student.ability, q.difficulty)\n",
        "    corr = K_ABILITY_UPDATE * (result - p_exp)\n",
        "    old = student.ability\n",
        "    student.ability = np.clip(student.ability + corr, 0, 1000)\n",
        "    h_cost = compute_h_cost(student, q)\n",
        "    student.h_cost = h_cost\n",
        "    #if student.group == \"G2\":\n",
        "        #student.h_cost = 1 - (student.ability / 1000)\n",
        "    return corr, p_exp, h_cost, old\n",
        "\n",
        "def select_question(student, day):\n",
        "    if not student.questions_state:\n",
        "        return None, 0, True, FALLBACK_LEVEL1, \"no_state\", 0, 0\n",
        "\n",
        "    # --- Nível 1: urgência ---\n",
        "    urgencies = {}\n",
        "    for st in SUBTEMAS:\n",
        "        dt = day - student.subtema_last_seen[st]\n",
        "        h = student.subtema_h[st]\n",
        "        p_ret = 0.5 ** (dt * student.h_cost / h)\n",
        "        if p_ret < student.threshold:\n",
        "            urgencies[st] = p_ret\n",
        "\n",
        "    if not urgencies:\n",
        "        return None, 0, True, FALLBACK_LEVEL1, FB_REASON_NO_URGENT_SUBTOPIC, 0, 0\n",
        "\n",
        "    chosen_st = min(urgencies, key=urgencies.get)\n",
        "\n",
        "    # --- Candidatos ideais (com faixa e MSI) ---\n",
        "    candidates = [q for q in student.questions_state.values()\n",
        "                  if q.subtema == chosen_st\n",
        "                  and abs(q.difficulty - student.ability) <= DIFFICULTY_RANGE_MARGIN\n",
        "                  and (q.last_day_seen == 0 or day - q.last_day_seen >= MIN_SPACING_INTERVAL)]\n",
        "\n",
        "    is_fb = False\n",
        "    fb_stage = FALLBACK_NONE\n",
        "    reason = FB_REASON_OK\n",
        "\n",
        "    if not candidates:\n",
        "        # Fallback nível 2\n",
        "        candidates = [q for q in student.questions_state.values() if q.subtema == chosen_st]\n",
        "        if not candidates:\n",
        "            return None, 0, True, FALLBACK_LEVEL2, FB_REASON_NO_ITEMS_IN_RANGE, 0, 0\n",
        "\n",
        "        is_fb = True\n",
        "        fb_stage = FALLBACK_LEVEL2\n",
        "        reason = FB_REASON_USED_ALL_SUBTEMA\n",
        "\n",
        "    # Escolhe a melhor questão entre as disponíveis\n",
        "    best_q = min(candidates, key=lambda q: abs(simple_logistic_prob(student.ability, q.difficulty) - 0.5))\n",
        "\n",
        "    dt = day - student.subtema_last_seen[chosen_st]\n",
        "    h = student.subtema_h[chosen_st]\n",
        "    p_est, retention, h_cost = generalized_probability(student, best_q, dt, h, student.h_cost)\n",
        "\n",
        "    return best_q, p_est, is_fb, fb_stage, reason, retention, h_cost\n",
        "\n",
        "all_sim_data = []\n",
        "all_post_data = []\n",
        "\n",
        "print(\"INICIANDO SIMULAÇÃO:\\n\")\n",
        "\n",
        "for horizonte in HORIZONTES_A_TESTAR:\n",
        "    print(f\"Horizonte: {horizonte} dias\")\n",
        "\n",
        "    np.random.seed(FIXED_SEED_INIT)\n",
        "    difficulties = get_truncated_normal(size=N_QUESTIONS)\n",
        "    subthemes = np.repeat(SUBTEMAS, N_QUESTIONS_PER_SUBTEMA)\n",
        "    np.random.shuffle(subthemes)\n",
        "    questions_pool = {i+1: Question(i+1, subthemes[i], difficulties[i]) for i in range(N_QUESTIONS)}\n",
        "\n",
        "    abilities = get_truncated_normal(size=N_STUDENTS)\n",
        "\n",
        "    if horizonte == HORIZONTES_A_TESTAR[0]:\n",
        "        plt.figure(figsize=(12,5))\n",
        "        plt.subplot(1,2,1)\n",
        "        sns.histplot(abilities, bins=20, kde=True, color='skyblue')\n",
        "        plt.title('Distribuição Inicial de Habilidade dos Alunos')\n",
        "        plt.subplot(1,2,2)\n",
        "        sns.histplot(difficulties, bins=20, kde=True, color='salmon')\n",
        "        plt.title('Distribuição Inicial de Dificuldade das Questões')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    for threshold in THRESHOLDS_P:\n",
        "        for run in range(1, N_ROUNDS+1):\n",
        "            np.random.seed(FIXED_SEED_INIT + run*1000 + int(threshold*100))\n",
        "\n",
        "            students = []\n",
        "            for i in range(N_STUDENTS):\n",
        "                group = \"G1\" if i < N_GROUP else \"G2\"\n",
        "                s = Student(i+1, group, threshold, abilities[i])\n",
        "                s.questions_state = {q.q_id: Question(q.q_id, q.subtema, q.difficulty) for q in questions_pool.values()}\n",
        "                students.append(s)\n",
        "\n",
        "            logs = []\n",
        "            for day in tqdm(range(1, horizonte+1), desc=f\"p={threshold} Run {run}\", leave=False):\n",
        "                for student in students:\n",
        "                  praticadas_no_dia = 0\n",
        "\n",
        "                  while praticadas_no_dia < CARGA_PRATICA:\n",
        "                    q, p_est, is_fb, fb_stage, fb_reason, retention, h_cost = select_question(student, day)\n",
        "                    if q is None and fb_stage == FALLBACK_LEVEL1:\n",
        "                        break\n",
        "\n",
        "                    if q is None:\n",
        "                        continue\n",
        "\n",
        "                    dt = day - student.subtema_last_seen[q.subtema]\n",
        "                    h_dpg = student.subtema_h[q.subtema]\n",
        "                    p_acerto = p_est #generalized_probability(student, q, dt, h_dpg, student.h_cost)\n",
        "\n",
        "                    result = sample_with_overdispersion(p_acerto)\n",
        "\n",
        "                    init_ability = student.ability\n",
        "                    init_correct = student.subtema_correct_streak[q.subtema]\n",
        "                    init_error = student.subtema_error_streak[q.subtema]\n",
        "\n",
        "                    corr, p_update, h_cost, _ = update_ability(student, q, result)\n",
        "                    update_half_life(q, student, result)\n",
        "\n",
        "                    final_correct = student.subtema_correct_streak[q.subtema]\n",
        "                    final_error = student.subtema_error_streak[q.subtema]\n",
        "\n",
        "                    student.subtema_last_seen[q.subtema] = day\n",
        "                    q.last_day_seen = day\n",
        "\n",
        "                    logs.append({\n",
        "                        'q_difficulty': q.difficulty,\n",
        "                        'h_cost': h_cost,\n",
        "                        'C ou A-HLR': retention,\n",
        "\n",
        "                        'run': run, 'horizonte_dias': horizonte, 'day': day,\n",
        "                        'group': student.group, 'p_limiar': threshold,\n",
        "                        'student_id': student.s_id,\n",
        "                        'ability_start': init_ability, 'ability_correction': corr,\n",
        "                        'ability_end': student.ability, 'prob_update_model': p_update,\n",
        "                        'h_cost_end': student.h_cost,\n",
        "                        'is_fallback': is_fb, 'fallback_stage': fb_stage, 'fallback_reason': fb_reason,\n",
        "                        'q_id': q.q_id, 'q_subtema': q.subtema, 'q_difficulty': q.difficulty,\n",
        "                        'result': result, 'p_acerto_real': p_acerto, 'p_est_revisao': p_est,\n",
        "                        'h_do_subtema': h_dpg, 'h_final': student.subtema_h[q.subtema],\n",
        "                        'dt': dt,\n",
        "                        'q_correct_start': init_correct, 'q_error_start': init_error,\n",
        "                        'q_correct_end': final_correct, 'q_error_end': final_error,\n",
        "                    })\n",
        "                    praticadas_no_dia += 1\n",
        "\n",
        "            df_run = pd.DataFrame(logs)\n",
        "            df_run['algoritmo'] = df_run.apply(lambda x: f\"{x.group} p={x.p_limiar}\", axis=1)\n",
        "            all_sim_data.append(df_run)\n",
        "\n",
        "            # Pós-teste\n",
        "            post = []\n",
        "            test_day = horizonte + 1\n",
        "            for student in students:\n",
        "                for q in student.questions_state.values():\n",
        "                    dt = test_day - student.subtema_last_seen[q.subtema]\n",
        "                    h = student.subtema_h[q.subtema]\n",
        "                    p, retention, h_cost = generalized_probability(student, q, dt, h, student.h_cost)\n",
        "                    res = 1 if np.random.rand() < p else 0\n",
        "                    post.append({\n",
        "                        'run': run, 'horizonte_dias': horizonte,\n",
        "                        'group': student.group, 'p_limiar': threshold,\n",
        "                        'algoritmo': f\"{student.group} p={threshold}\",\n",
        "                        'student_id': student.s_id, 'result': res\n",
        "                    })\n",
        "            all_post_data.append(pd.DataFrame(post))\n",
        "\n",
        "#  RESULTADOS FINAIS\n",
        "df_sim = pd.concat(all_sim_data, ignore_index=True)\n",
        "df_post = pd.concat(all_post_data, ignore_index=True)\n",
        "\n",
        "df_sim['algoritmo'] = df_sim['group'] + ' p=' + df_sim['p_limiar'].astype(str)\n",
        "df_post['algoritmo'] = df_post['group'] + ' p=' + df_post['p_limiar'].astype(str)\n",
        "\n",
        "# Salvar CSVs\n",
        "df_sim.to_csv(\"SIMULACAO_G1_HLR_vs_G2_AHLR_COMPLETA.csv\", index=False, encoding=\"utf-8\")\n",
        "df_post.to_csv(\"POSTTEST_G1_HLR_vs_G2_AHLR_COMPLETA.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "#  GRÁFICOS E ANÁLISES\n",
        "def plot_metrics_by_horizon(df, title, y_label, metric):\n",
        "    #plt.figure(figsize=(15, 8))\n",
        "    plt.figure(figsize=(20, 10), dpi=300)\n",
        "    df_agg = df.groupby(['run', 'algoritmo', 'horizonte_dias'])[metric].mean().reset_index()\n",
        "    df_agg['grupo_completo'] = df_agg['algoritmo'] + ' (H:' + df_agg['horizonte_dias'].astype(str) + ')'\n",
        "    sns.barplot(x='grupo_completo', y=metric, data=df_agg, hue='horizonte_dias', palette='viridis', errorbar=('ci', 95))\n",
        "    plt.title(title)\n",
        "    plt.ylabel(y_label + ' (Média das Rodadas com IC 95%)')\n",
        "    plt.xlabel('Algoritmo de Agendamento')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend(title='Horizonte (Dias)')\n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "df_acc = (\n",
        "    df_sim\n",
        "    .groupby(['run', 'algoritmo', 'horizonte_dias'])['result']\n",
        "    .mean()\n",
        "    .reset_index(name='accuracy')\n",
        ")\n",
        "\n",
        "plot_metrics_by_horizon(\n",
        "    df_sim,\n",
        "    'Taxa de Acerto Média DURANTE a Prática',\n",
        "    'Taxa de Acerto',\n",
        "    'result'\n",
        ")\n",
        "\n",
        "plot_metrics_by_horizon(\n",
        "    df_post,\n",
        "    'Retenção Final (Dia N+1) - Taxa de Acerto no Pós-Teste',\n",
        "    'Taxa de Acerto no Pós-Teste',\n",
        "    'result'\n",
        ")\n",
        "\n",
        "\n",
        "def plot_g1_vs_g2_by_horizon(df, title, y_label, metric):\n",
        "    plt.figure(figsize=(14, 7), dpi=300)\n",
        "\n",
        "    df_agg = (\n",
        "        df.groupby(['run', 'group', 'horizonte_dias'])[metric]\n",
        "          .mean()\n",
        "          .reset_index()\n",
        "    )\n",
        "\n",
        "    ax = sns.barplot(\n",
        "        data=df_agg,\n",
        "        x='horizonte_dias',\n",
        "        y=metric,\n",
        "        hue='group',\n",
        "        errorbar=('ci', 95),\n",
        "        palette='Set2'\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        if not np.isnan(height):\n",
        "            ax.annotate(\n",
        "                f'{height*100:.1f}%',\n",
        "                (p.get_x() + p.get_width() / 2., height),\n",
        "                ha='center',\n",
        "                va='bottom',\n",
        "                fontsize=9,\n",
        "                xytext=(0, 4),\n",
        "                textcoords='offset points'\n",
        "            )\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.ylabel(y_label + ' (%)')\n",
        "    plt.xlabel('Horizonte de Previsão (dias)')\n",
        "    plt.legend(title='Algoritmo')\n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "df_sim_p07 = df_sim[df_sim['p_limiar'] == 0.7]\n",
        "df_sim_p09 = df_sim[df_sim['p_limiar'] == 0.9]\n",
        "\n",
        "plot_g1_vs_g2_by_horizon(\n",
        "    df_sim_p07,\n",
        "    'Taxa de Acerto Média DURANTE a Prática — G1 vs G2 (p = 0.7)',\n",
        "    'Taxa de Acerto',\n",
        "    'result'\n",
        ")\n",
        "\n",
        "plot_g1_vs_g2_by_horizon(\n",
        "    df_sim_p09,\n",
        "    'Taxa de Acerto Média DURANTE a Prática — G1 vs G2 (p = 0.9)',\n",
        "    'Taxa de Acerto',\n",
        "    'result'\n",
        ")\n",
        "\n",
        "def plot_linhas_g1_g2(df_acc, p_valor, titulo):\n",
        "    df_plot = df_acc[df_acc['algoritmo'].str.contains(f'p={p_valor}')].copy()\n",
        "\n",
        "    df_plot['grupo'] = df_plot['algoritmo'].str.extract(r'(G\\d)')\n",
        "\n",
        "    plt.figure(figsize=(10, 6), dpi=300)\n",
        "\n",
        "    sns.lineplot(\n",
        "        data=df_plot,\n",
        "        x='horizonte_dias',\n",
        "        y='accuracy',\n",
        "        hue='grupo',\n",
        "        marker='o',\n",
        "        errorbar=('ci', 95)\n",
        "    )\n",
        "\n",
        "    plt.title(titulo)\n",
        "    plt.xlabel('Horizonte (dias)')\n",
        "    plt.ylabel('Taxa de Acerto Média')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.legend(title='Grupo')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_linhas_g1_g2(\n",
        "    df_acc,\n",
        "    p_valor=0.7,\n",
        "    titulo='Evolução da Taxa de Acerto Durante a Prática (p = 0.7)'\n",
        ")\n",
        "\n",
        "plot_linhas_g1_g2(\n",
        "    df_acc,\n",
        "    p_valor=0.9,\n",
        "    titulo='Evolução da Taxa de Acerto Durante a Prática (p = 0.9)'\n",
        ")\n",
        "\n",
        "df_acc = (\n",
        "    df_sim\n",
        "    .groupby(['run', 'group', 'p_limiar', 'horizonte_dias'])['result']\n",
        "    .mean()\n",
        "    .reset_index(name='accuracy')\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 7), dpi=300)\n",
        "\n",
        "sns.lineplot(\n",
        "    data=df_acc,\n",
        "    x='horizonte_dias',\n",
        "    y='accuracy',\n",
        "    hue='group',\n",
        "    style='p_limiar',\n",
        "    markers=True,\n",
        "    dashes=True,\n",
        "    errorbar=('ci', 95)\n",
        ")\n",
        "\n",
        "plt.title('Evolução da Taxa de Acerto — G1 vs G2 para p = 0.7 e p = 0.9')\n",
        "plt.xlabel('Horizonte (dias)')\n",
        "plt.ylabel('Taxa de Acerto Média')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend(title='Grupo / Limiar')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# RETENÇÃO FINAL\n",
        "\n",
        "def plot_retencao_por_horizonte(df_post, p_valor, titulo):\n",
        "    df_plot = (\n",
        "        df_post[df_post['p_limiar'] == p_valor]\n",
        "        .groupby(['run', 'group', 'horizonte_dias'])['result']\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(10, 6), dpi=300)\n",
        "\n",
        "    sns.barplot(\n",
        "        data=df_plot,\n",
        "        x='horizonte_dias',\n",
        "        y='result',\n",
        "        hue='group',\n",
        "        errorbar=('ci', 95),\n",
        "        palette='Set2'\n",
        "    )\n",
        "\n",
        "    plt.title(titulo)\n",
        "    plt.xlabel('Horizonte de Revisão (dias)')\n",
        "    plt.ylabel('Taxa de Acerto no Pós-Teste')\n",
        "    plt.legend(title='Algoritmo')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_retencao_por_horizonte(\n",
        "    df_post,\n",
        "    p_valor=0.7,\n",
        "    titulo='Retenção Final (Dia N+1) — G1 vs G2 (p = 0.7)'\n",
        ")\n",
        "\n",
        "plot_retencao_por_horizonte(\n",
        "    df_post,\n",
        "    p_valor=0.9,\n",
        "    titulo='Retenção Final (Dia N+1) — G1 vs G2 (p = 0.9)'\n",
        ")\n",
        "\n",
        "\n",
        "# Fallback\n",
        "print(\"\\n--- Frequência Média de Agendamento por Fallback (Indica Saturação) ---\")\n",
        "df_fb = df_sim.groupby(['run', 'algoritmo', 'horizonte_dias'])['is_fallback'].mean().reset_index()\n",
        "df_fb['porcentagem'] = df_fb['is_fallback'] * 100\n",
        "df_fb['grupo_h'] = df_fb['algoritmo'] + ' (H:' + df_fb['horizonte_dias'].astype(str) + ')'\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(x='grupo_h', y='porcentagem', hue='horizonte_dias', data=df_fb, palette='magma', errorbar=('ci', 95))\n",
        "plt.title('Frequência de Fallback (%)')\n",
        "plt.ylabel('Fallbacks (%)')\n",
        "plt.xlabel('Algoritmo e Horizonte')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Carga por subtema\n",
        "print(\"\\n--- Distribuição da Carga de Revisão por Subtema ---\")\n",
        "df_carga_por_aluno = df_sim.groupby(['run', 'algoritmo', 'horizonte_dias', 'student_id', 'q_subtema']).size().reset_index(name='respostas_aluno')\n",
        "df_carga_agg = df_carga_por_aluno.groupby(['run', 'algoritmo', 'horizonte_dias', 'q_subtema'])['respostas_aluno'].mean().reset_index(name='media_por_aluno')\n",
        "df_total = df_carga_agg.groupby(['run', 'algoritmo', 'horizonte_dias'])['media_por_aluno'].sum().reset_index()\n",
        "df_total['q_subtema'] = 'Total Geral'\n",
        "df_carga_full = pd.concat([df_carga_agg, df_total], ignore_index=True)\n",
        "df_carga_final = df_carga_full.groupby(['algoritmo', 'q_subtema', 'horizonte_dias'])['media_por_aluno'].mean().reset_index()\n",
        "df_carga_final['algoritmo_h'] = df_carga_final['algoritmo'] + ' (H:' + df_carga_final['horizonte_dias'].astype(str) + ')'\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.barplot(x='q_subtema', y='media_por_aluno', hue='algoritmo_h',\n",
        "            data=df_carga_final[df_carga_final['q_subtema'] != 'Total Geral'], palette='Spectral')\n",
        "plt.title('Distribuição Média de Revisões por Subtema (por aluno)')\n",
        "plt.ylabel('Média de Respostas por Aluno')\n",
        "plt.xlabel('Subtema')\n",
        "plt.legend(title='Algoritmo e Horizonte', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n[TABELA DE CARGA DE REVISÃO — Média de Respostas por Aluno]\")\n",
        "df_pivot = df_carga_final[df_carga_final['q_subtema'].isin(SUBTEMAS + ['Total Geral'])].pivot_table(\n",
        "    index=['horizonte_dias', 'q_subtema'], columns='algoritmo', values='media_por_aluno', fill_value=0).round(2)\n",
        "print(df_pivot)\n",
        "\n",
        "# Análise estatística\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANÁLISE ESTATÍSTICA FORMAL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_acc = df_sim.groupby(['run', 'algoritmo', 'horizonte_dias'])['result'].mean().reset_index(name='accuracy')\n",
        "df_acc['combo'] = df_acc['algoritmo'] + '_H' + df_acc['horizonte_dias'].astype(str)\n",
        "anova_acc = stats.f_oneway(*[g['accuracy'] for _, g in df_acc.groupby('combo')])\n",
        "print(f\"\\nTaxa de Acerto na Prática → ANOVA: F={anova_acc.statistic:.2f}, p={anova_acc.pvalue:.2e}\")\n",
        "if anova_acc.pvalue < 0.05:\n",
        "    tukey_acc = pairwise_tukeyhsd(df_acc['accuracy'], df_acc['combo'])\n",
        "    print(tukey_acc)\n",
        "\n",
        "df_ret = df_post.groupby(['run', 'algoritmo', 'horizonte_dias'])['result'].mean().reset_index(name='retention')\n",
        "df_ret['combo'] = df_ret['algoritmo'] + '_H' + df_ret['horizonte_dias'].astype(str)\n",
        "anova_ret = stats.f_oneway(*[g['retention'] for _, g in df_ret.groupby('combo')])\n",
        "print(f\"\\nRetenção Final (Pós-teste) → ANOVA: F={anova_ret.statistic:.2f}, p={anova_ret.pvalue:.2e}\")\n",
        "if anova_ret.pvalue < 0.05:\n",
        "    tukey_ret = pairwise_tukeyhsd(df_ret['retention'], df_ret['combo'])\n",
        "    print(tukey_ret)\n",
        "\n",
        "# Repetições\n",
        "print(\"\\n--- Total de Repetições de Questões (Interações > 1) ---\")\n",
        "df_freq = df_sim.groupby(['run', 'algoritmo', 'horizonte_dias', 'student_id', 'q_id']).size().reset_index(name='freq')\n",
        "df_freq['repeticoes'] = df_freq['freq'] - 1\n",
        "df_rep = df_freq.groupby(['run', 'algoritmo', 'horizonte_dias'])['repeticoes'].sum().reset_index()\n",
        "df_rep['media_por_aluno'] = df_rep['repeticoes'] / N_GROUP\n",
        "df_rep_final = df_rep.groupby(['algoritmo', 'horizonte_dias'])['media_por_aluno'].mean().reset_index()\n",
        "df_rep_pivot = df_rep_final.pivot(index='horizonte_dias', columns='algoritmo', values='media_por_aluno').round(2)\n",
        "print(\"\\nMédia de Repetições por Aluno:\")\n",
        "print(df_rep_pivot)\n",
        "\n",
        "#  FALLBACK\n",
        "\n",
        "print(\"\\n--- Frequência Média de Agendamento por Fallback (Indica Saturação) ---\")\n",
        "\n",
        "df_fb = (\n",
        "    df_sim\n",
        "    .groupby(['run', 'group', 'p_limiar', 'horizonte_dias'])['is_fallback']\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "df_fb['porcentagem'] = df_fb['is_fallback'] * 100\n",
        "\n",
        "df_fb_p07 = df_fb[df_fb['p_limiar'] == 0.7]\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=300)\n",
        "\n",
        "sns.barplot(\n",
        "    data=df_fb_p07,\n",
        "    x='horizonte_dias',\n",
        "    y='porcentagem',\n",
        "    hue='group',\n",
        "    errorbar=('ci', 95),\n",
        "    palette='Set2'\n",
        ")\n",
        "\n",
        "plt.title('Frequência de Fallback (%) — p = 0.7')\n",
        "plt.xlabel('Horizonte (dias)')\n",
        "plt.ylabel('Fallback (%)')\n",
        "plt.legend(title='Algoritmo')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df_fb_p09 = df_fb[df_fb['p_limiar'] == 0.9]\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=300)\n",
        "\n",
        "sns.barplot(\n",
        "    data=df_fb_p09,\n",
        "    x='horizonte_dias',\n",
        "    y='porcentagem',\n",
        "    hue='group',\n",
        "    errorbar=('ci', 95),\n",
        "    palette='Set2'\n",
        ")\n",
        "\n",
        "plt.title('Frequência de Fallback (%) — p = 0.9')\n",
        "plt.xlabel('Horizonte (dias)')\n",
        "plt.ylabel('Fallback (%)')\n",
        "plt.legend(title='Algoritmo')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Evolução Temporal das Métricas ---\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=df_acc, x='horizonte_dias', y='accuracy', hue='algoritmo', marker='o', errorbar=('ci', 95))\n",
        "plt.title('Evolução da Taxa de Acerto Durante a Prática')\n",
        "plt.xlabel('Horizonte (dias)')\n",
        "plt.ylabel('Taxa de Acerto Média')\n",
        "plt.grid(True, linestyle='--')\n",
        "plt.legend(title='Algoritmo')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=df_ret, x='horizonte_dias', y='retention', hue='algoritmo', marker='o', errorbar=('ci', 95))\n",
        "plt.title('Evolução da Retenção no Pós-Teste')\n",
        "plt.xlabel('Horizonte (dias)')\n",
        "plt.ylabel('Taxa de Retenção Média')\n",
        "plt.grid(True, linestyle='--')\n",
        "plt.legend(title='Algoritmo')\n",
        "plt.show()\n",
        "\n",
        "# EXPORTAÇÃO FINAL\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SALVANDO ARQUIVOS FINAIS...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "excel_filename = \"RESULTADOS_COMPLETOS_HLR_vs_AHLR.xlsx\"\n",
        "with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
        "    df_sim.to_excel(writer, sheet_name=\"Simulacao_Diaria\", index=False)\n",
        "    #df_post.to_excel(writer, sheet_name=\"Post_Teste\", index=False)\n",
        "\n",
        "    summary_acc = df_sim.groupby(['algoritmo', 'horizonte_dias'])['result'].mean().reset_index()\n",
        "    summary_acc.rename(columns={'result': 'Taxa_Acerto_Pratica'}, inplace=True)\n",
        "    summary_ret = df_post.groupby(['algoritmo', 'horizonte_dias'])['result'].mean().reset_index()\n",
        "    summary_ret.rename(columns={'result': 'Taxa_Retencao_PosTeste'}, inplace=True)\n",
        "    summary = pd.merge(summary_acc, summary_ret, on=['algoritmo', 'horizonte_dias'], how='outer').round(4)\n",
        "    summary.to_excel(writer, sheet_name=\"Resumo_Metricas\", index=False)\n",
        "\n",
        "    df_pivot.to_excel(writer, sheet_name=\"Carga_por_Subtema\", index=True)\n",
        "    df_rep_pivot.to_excel(writer, sheet_name=\"Repeticoes_por_Aluno\", index=True)\n",
        "\n",
        "print(f\"Arquivos salvos com sucesso!\")\n",
        "print(f\"   → SIMULACAO_G1_HLR_vs_G2_AHLR_COMPLETA.csv\")\n",
        "print(f\"   → POSTTEST_G1_HLR_vs_G2_AHLR_COMPLETA.csv\")\n",
        "print(f\"   → {excel_filename}\")\n",
        "print(f\"     Abas: Simulacao_Diaria | Post_Teste | Resumo_Metricas | Carga_por_Subtema | Repeticoes_por_Aluno\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n"
      ]
    }
  ]
}